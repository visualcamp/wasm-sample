/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_CONFIGURATION_TFLITE_H_
#define FLATBUFFERS_GENERATED_CONFIGURATION_TFLITE_H_

#include "flatbuffers/flatbuffers.h"

namespace tflite {

struct ComputeSettings;
struct ComputeSettingsT;

struct NNAPISettings;
struct NNAPISettingsT;

struct GPUSettings;
struct GPUSettingsT;

struct HexagonSettings;
struct HexagonSettingsT;

struct XNNPackSettings;
struct XNNPackSettingsT;

struct EdgeTpuSettings;
struct EdgeTpuSettingsT;

struct CPUSettings;
struct CPUSettingsT;

struct TFLiteSettings;
struct TFLiteSettingsT;

struct FallbackSettings;
struct FallbackSettingsT;

enum ExecutionPreference {
  ExecutionPreference_ANY = 0,
  ExecutionPreference_LOW_LATENCY = 1,
  ExecutionPreference_LOW_POWER = 2,
  ExecutionPreference_FORCE_CPU = 3,
  ExecutionPreference_MIN = ExecutionPreference_ANY,
  ExecutionPreference_MAX = ExecutionPreference_FORCE_CPU
};

inline const ExecutionPreference (&EnumValuesExecutionPreference())[4] {
  static const ExecutionPreference values[] = {
    ExecutionPreference_ANY,
    ExecutionPreference_LOW_LATENCY,
    ExecutionPreference_LOW_POWER,
    ExecutionPreference_FORCE_CPU
  };
  return values;
}

inline const char * const *EnumNamesExecutionPreference() {
  static const char * const names[5] = {
    "ANY",
    "LOW_LATENCY",
    "LOW_POWER",
    "FORCE_CPU",
    nullptr
  };
  return names;
}

inline const char *EnumNameExecutionPreference(ExecutionPreference e) {
  if (flatbuffers::IsOutRange(e, ExecutionPreference_ANY, ExecutionPreference_FORCE_CPU)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesExecutionPreference()[index];
}

enum Delegate {
  Delegate_NONE = 0,
  Delegate_NNAPI = 1,
  Delegate_GPU = 2,
  Delegate_HEXAGON = 3,
  Delegate_XNNPACK = 4,
  Delegate_EDGETPU = 5,
  Delegate_MIN = Delegate_NONE,
  Delegate_MAX = Delegate_EDGETPU
};

inline const Delegate (&EnumValuesDelegate())[6] {
  static const Delegate values[] = {
    Delegate_NONE,
    Delegate_NNAPI,
    Delegate_GPU,
    Delegate_HEXAGON,
    Delegate_XNNPACK,
    Delegate_EDGETPU
  };
  return values;
}

inline const char * const *EnumNamesDelegate() {
  static const char * const names[7] = {
    "NONE",
    "NNAPI",
    "GPU",
    "HEXAGON",
    "XNNPACK",
    "EDGETPU",
    nullptr
  };
  return names;
}

inline const char *EnumNameDelegate(Delegate e) {
  if (flatbuffers::IsOutRange(e, Delegate_NONE, Delegate_EDGETPU)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesDelegate()[index];
}

enum NNAPIExecutionPreference {
  NNAPIExecutionPreference_UNDEFINED = 0,
  NNAPIExecutionPreference_NNAPI_LOW_POWER = 1,
  NNAPIExecutionPreference_NNAPI_FAST_SINGLE_ANSWER = 2,
  NNAPIExecutionPreference_NNAPI_SUSTAINED_SPEED = 3,
  NNAPIExecutionPreference_MIN = NNAPIExecutionPreference_UNDEFINED,
  NNAPIExecutionPreference_MAX = NNAPIExecutionPreference_NNAPI_SUSTAINED_SPEED
};

inline const NNAPIExecutionPreference (&EnumValuesNNAPIExecutionPreference())[4] {
  static const NNAPIExecutionPreference values[] = {
    NNAPIExecutionPreference_UNDEFINED,
    NNAPIExecutionPreference_NNAPI_LOW_POWER,
    NNAPIExecutionPreference_NNAPI_FAST_SINGLE_ANSWER,
    NNAPIExecutionPreference_NNAPI_SUSTAINED_SPEED
  };
  return values;
}

inline const char * const *EnumNamesNNAPIExecutionPreference() {
  static const char * const names[5] = {
    "UNDEFINED",
    "NNAPI_LOW_POWER",
    "NNAPI_FAST_SINGLE_ANSWER",
    "NNAPI_SUSTAINED_SPEED",
    nullptr
  };
  return names;
}

inline const char *EnumNameNNAPIExecutionPreference(NNAPIExecutionPreference e) {
  if (flatbuffers::IsOutRange(e, NNAPIExecutionPreference_UNDEFINED, NNAPIExecutionPreference_NNAPI_SUSTAINED_SPEED)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesNNAPIExecutionPreference()[index];
}

enum NNAPIExecutionPriority {
  NNAPIExecutionPriority_NNAPI_PRIORITY_UNDEFINED = 0,
  NNAPIExecutionPriority_NNAPI_PRIORITY_LOW = 1,
  NNAPIExecutionPriority_NNAPI_PRIORITY_MEDIUM = 2,
  NNAPIExecutionPriority_NNAPI_PRIORITY_HIGH = 3,
  NNAPIExecutionPriority_MIN = NNAPIExecutionPriority_NNAPI_PRIORITY_UNDEFINED,
  NNAPIExecutionPriority_MAX = NNAPIExecutionPriority_NNAPI_PRIORITY_HIGH
};

inline const NNAPIExecutionPriority (&EnumValuesNNAPIExecutionPriority())[4] {
  static const NNAPIExecutionPriority values[] = {
    NNAPIExecutionPriority_NNAPI_PRIORITY_UNDEFINED,
    NNAPIExecutionPriority_NNAPI_PRIORITY_LOW,
    NNAPIExecutionPriority_NNAPI_PRIORITY_MEDIUM,
    NNAPIExecutionPriority_NNAPI_PRIORITY_HIGH
  };
  return values;
}

inline const char * const *EnumNamesNNAPIExecutionPriority() {
  static const char * const names[5] = {
    "NNAPI_PRIORITY_UNDEFINED",
    "NNAPI_PRIORITY_LOW",
    "NNAPI_PRIORITY_MEDIUM",
    "NNAPI_PRIORITY_HIGH",
    nullptr
  };
  return names;
}

inline const char *EnumNameNNAPIExecutionPriority(NNAPIExecutionPriority e) {
  if (flatbuffers::IsOutRange(e, NNAPIExecutionPriority_NNAPI_PRIORITY_UNDEFINED, NNAPIExecutionPriority_NNAPI_PRIORITY_HIGH)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesNNAPIExecutionPriority()[index];
}

enum GPUBackend {
  GPUBackend_UNSET = 0,
  GPUBackend_OPENCL = 1,
  GPUBackend_OPENGL = 2,
  GPUBackend_MIN = GPUBackend_UNSET,
  GPUBackend_MAX = GPUBackend_OPENGL
};

inline const GPUBackend (&EnumValuesGPUBackend())[3] {
  static const GPUBackend values[] = {
    GPUBackend_UNSET,
    GPUBackend_OPENCL,
    GPUBackend_OPENGL
  };
  return values;
}

inline const char * const *EnumNamesGPUBackend() {
  static const char * const names[4] = {
    "UNSET",
    "OPENCL",
    "OPENGL",
    nullptr
  };
  return names;
}

inline const char *EnumNameGPUBackend(GPUBackend e) {
  if (flatbuffers::IsOutRange(e, GPUBackend_UNSET, GPUBackend_OPENGL)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesGPUBackend()[index];
}

namespace EdgeTpuSettings_ {

enum PowerState {
  PowerState_UNDEFINED = 0,
  PowerState_TPU_CORE_OFF = 1,
  PowerState_READY = 2,
  PowerState_READY_WITH_RETENTION = 3,
  PowerState_ACTIVE_MIN_POWER = 4,
  PowerState_ACTIVE_LOW_POWER = 5,
  PowerState_ACTIVE = 6,
  PowerState_OVER_DRIVE = 7,
  PowerState_MIN = PowerState_UNDEFINED,
  PowerState_MAX = PowerState_OVER_DRIVE
};

inline const PowerState (&EnumValuesPowerState())[8] {
  static const PowerState values[] = {
    PowerState_UNDEFINED,
    PowerState_TPU_CORE_OFF,
    PowerState_READY,
    PowerState_READY_WITH_RETENTION,
    PowerState_ACTIVE_MIN_POWER,
    PowerState_ACTIVE_LOW_POWER,
    PowerState_ACTIVE,
    PowerState_OVER_DRIVE
  };
  return values;
}

inline const char * const *EnumNamesPowerState() {
  static const char * const names[9] = {
    "UNDEFINED",
    "TPU_CORE_OFF",
    "READY",
    "READY_WITH_RETENTION",
    "ACTIVE_MIN_POWER",
    "ACTIVE_LOW_POWER",
    "ACTIVE",
    "OVER_DRIVE",
    nullptr
  };
  return names;
}

inline const char *EnumNamePowerState(PowerState e) {
  if (flatbuffers::IsOutRange(e, PowerState_UNDEFINED, PowerState_OVER_DRIVE)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesPowerState()[index];
}

}  // namespace EdgeTpuSettings_

struct ComputeSettingsT : public flatbuffers::NativeTable {
  typedef ComputeSettings TableType;
  tflite::ExecutionPreference preference;
  std::unique_ptr<tflite::TFLiteSettingsT> tflite_settings;
  std::string model_namespace_for_statistics;
  std::string model_identifier_for_statistics;
  ComputeSettingsT()
      : preference(tflite::ExecutionPreference_ANY) {
  }
};

struct ComputeSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef ComputeSettingsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_PREFERENCE = 4,
    VT_TFLITE_SETTINGS = 6,
    VT_MODEL_NAMESPACE_FOR_STATISTICS = 8,
    VT_MODEL_IDENTIFIER_FOR_STATISTICS = 10
  };
  tflite::ExecutionPreference preference() const {
    return static_cast<tflite::ExecutionPreference>(GetField<int32_t>(VT_PREFERENCE, 0));
  }
  const tflite::TFLiteSettings *tflite_settings() const {
    return GetPointer<const tflite::TFLiteSettings *>(VT_TFLITE_SETTINGS);
  }
  const flatbuffers::String *model_namespace_for_statistics() const {
    return GetPointer<const flatbuffers::String *>(VT_MODEL_NAMESPACE_FOR_STATISTICS);
  }
  const flatbuffers::String *model_identifier_for_statistics() const {
    return GetPointer<const flatbuffers::String *>(VT_MODEL_IDENTIFIER_FOR_STATISTICS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, VT_PREFERENCE) &&
           VerifyOffset(verifier, VT_TFLITE_SETTINGS) &&
           verifier.VerifyTable(tflite_settings()) &&
           VerifyOffset(verifier, VT_MODEL_NAMESPACE_FOR_STATISTICS) &&
           verifier.VerifyString(model_namespace_for_statistics()) &&
           VerifyOffset(verifier, VT_MODEL_IDENTIFIER_FOR_STATISTICS) &&
           verifier.VerifyString(model_identifier_for_statistics()) &&
           verifier.EndTable();
  }
  ComputeSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(ComputeSettingsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<ComputeSettings> Pack(flatbuffers::FlatBufferBuilder &_fbb, const ComputeSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct ComputeSettingsBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_preference(tflite::ExecutionPreference preference) {
    fbb_.AddElement<int32_t>(ComputeSettings::VT_PREFERENCE, static_cast<int32_t>(preference), 0);
  }
  void add_tflite_settings(flatbuffers::Offset<tflite::TFLiteSettings> tflite_settings) {
    fbb_.AddOffset(ComputeSettings::VT_TFLITE_SETTINGS, tflite_settings);
  }
  void add_model_namespace_for_statistics(flatbuffers::Offset<flatbuffers::String> model_namespace_for_statistics) {
    fbb_.AddOffset(ComputeSettings::VT_MODEL_NAMESPACE_FOR_STATISTICS, model_namespace_for_statistics);
  }
  void add_model_identifier_for_statistics(flatbuffers::Offset<flatbuffers::String> model_identifier_for_statistics) {
    fbb_.AddOffset(ComputeSettings::VT_MODEL_IDENTIFIER_FOR_STATISTICS, model_identifier_for_statistics);
  }
  explicit ComputeSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ComputeSettingsBuilder &operator=(const ComputeSettingsBuilder &);
  flatbuffers::Offset<ComputeSettings> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<ComputeSettings>(end);
    return o;
  }
};

inline flatbuffers::Offset<ComputeSettings> CreateComputeSettings(
    flatbuffers::FlatBufferBuilder &_fbb,
    tflite::ExecutionPreference preference = tflite::ExecutionPreference_ANY,
    flatbuffers::Offset<tflite::TFLiteSettings> tflite_settings = 0,
    flatbuffers::Offset<flatbuffers::String> model_namespace_for_statistics = 0,
    flatbuffers::Offset<flatbuffers::String> model_identifier_for_statistics = 0) {
  ComputeSettingsBuilder builder_(_fbb);
  builder_.add_model_identifier_for_statistics(model_identifier_for_statistics);
  builder_.add_model_namespace_for_statistics(model_namespace_for_statistics);
  builder_.add_tflite_settings(tflite_settings);
  builder_.add_preference(preference);
  return builder_.Finish();
}

inline flatbuffers::Offset<ComputeSettings> CreateComputeSettingsDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    tflite::ExecutionPreference preference = tflite::ExecutionPreference_ANY,
    flatbuffers::Offset<tflite::TFLiteSettings> tflite_settings = 0,
    const char *model_namespace_for_statistics = nullptr,
    const char *model_identifier_for_statistics = nullptr) {
  auto model_namespace_for_statistics__ = model_namespace_for_statistics ? _fbb.CreateString(model_namespace_for_statistics) : 0;
  auto model_identifier_for_statistics__ = model_identifier_for_statistics ? _fbb.CreateString(model_identifier_for_statistics) : 0;
  return tflite::CreateComputeSettings(
      _fbb,
      preference,
      tflite_settings,
      model_namespace_for_statistics__,
      model_identifier_for_statistics__);
}

flatbuffers::Offset<ComputeSettings> CreateComputeSettings(flatbuffers::FlatBufferBuilder &_fbb, const ComputeSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct NNAPISettingsT : public flatbuffers::NativeTable {
  typedef NNAPISettings TableType;
  std::string accelerator_name;
  std::string cache_directory;
  std::string model_token;
  tflite::NNAPIExecutionPreference execution_preference;
  int32_t no_of_nnapi_instances_to_cache;
  std::unique_ptr<tflite::FallbackSettingsT> fallback_settings;
  bool allow_nnapi_cpu_on_android_10_plus;
  tflite::NNAPIExecutionPriority execution_priority;
  bool allow_dynamic_dimensions;
  bool allow_fp16_precision_for_fp32;
  NNAPISettingsT()
      : execution_preference(tflite::NNAPIExecutionPreference_UNDEFINED),
        no_of_nnapi_instances_to_cache(0),
        allow_nnapi_cpu_on_android_10_plus(false),
        execution_priority(tflite::NNAPIExecutionPriority_NNAPI_PRIORITY_UNDEFINED),
        allow_dynamic_dimensions(false),
        allow_fp16_precision_for_fp32(false) {
  }
};

struct NNAPISettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef NNAPISettingsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ACCELERATOR_NAME = 4,
    VT_CACHE_DIRECTORY = 6,
    VT_MODEL_TOKEN = 8,
    VT_EXECUTION_PREFERENCE = 10,
    VT_NO_OF_NNAPI_INSTANCES_TO_CACHE = 12,
    VT_FALLBACK_SETTINGS = 14,
    VT_ALLOW_NNAPI_CPU_ON_ANDROID_10_PLUS = 16,
    VT_EXECUTION_PRIORITY = 18,
    VT_ALLOW_DYNAMIC_DIMENSIONS = 20,
    VT_ALLOW_FP16_PRECISION_FOR_FP32 = 22
  };
  const flatbuffers::String *accelerator_name() const {
    return GetPointer<const flatbuffers::String *>(VT_ACCELERATOR_NAME);
  }
  const flatbuffers::String *cache_directory() const {
    return GetPointer<const flatbuffers::String *>(VT_CACHE_DIRECTORY);
  }
  const flatbuffers::String *model_token() const {
    return GetPointer<const flatbuffers::String *>(VT_MODEL_TOKEN);
  }
  tflite::NNAPIExecutionPreference execution_preference() const {
    return static_cast<tflite::NNAPIExecutionPreference>(GetField<int32_t>(VT_EXECUTION_PREFERENCE, 0));
  }
  int32_t no_of_nnapi_instances_to_cache() const {
    return GetField<int32_t>(VT_NO_OF_NNAPI_INSTANCES_TO_CACHE, 0);
  }
  const tflite::FallbackSettings *fallback_settings() const {
    return GetPointer<const tflite::FallbackSettings *>(VT_FALLBACK_SETTINGS);
  }
  bool allow_nnapi_cpu_on_android_10_plus() const {
    return GetField<uint8_t>(VT_ALLOW_NNAPI_CPU_ON_ANDROID_10_PLUS, 0) != 0;
  }
  tflite::NNAPIExecutionPriority execution_priority() const {
    return static_cast<tflite::NNAPIExecutionPriority>(GetField<int32_t>(VT_EXECUTION_PRIORITY, 0));
  }
  bool allow_dynamic_dimensions() const {
    return GetField<uint8_t>(VT_ALLOW_DYNAMIC_DIMENSIONS, 0) != 0;
  }
  bool allow_fp16_precision_for_fp32() const {
    return GetField<uint8_t>(VT_ALLOW_FP16_PRECISION_FOR_FP32, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_ACCELERATOR_NAME) &&
           verifier.VerifyString(accelerator_name()) &&
           VerifyOffset(verifier, VT_CACHE_DIRECTORY) &&
           verifier.VerifyString(cache_directory()) &&
           VerifyOffset(verifier, VT_MODEL_TOKEN) &&
           verifier.VerifyString(model_token()) &&
           VerifyField<int32_t>(verifier, VT_EXECUTION_PREFERENCE) &&
           VerifyField<int32_t>(verifier, VT_NO_OF_NNAPI_INSTANCES_TO_CACHE) &&
           VerifyOffset(verifier, VT_FALLBACK_SETTINGS) &&
           verifier.VerifyTable(fallback_settings()) &&
           VerifyField<uint8_t>(verifier, VT_ALLOW_NNAPI_CPU_ON_ANDROID_10_PLUS) &&
           VerifyField<int32_t>(verifier, VT_EXECUTION_PRIORITY) &&
           VerifyField<uint8_t>(verifier, VT_ALLOW_DYNAMIC_DIMENSIONS) &&
           VerifyField<uint8_t>(verifier, VT_ALLOW_FP16_PRECISION_FOR_FP32) &&
           verifier.EndTable();
  }
  NNAPISettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(NNAPISettingsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<NNAPISettings> Pack(flatbuffers::FlatBufferBuilder &_fbb, const NNAPISettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct NNAPISettingsBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_accelerator_name(flatbuffers::Offset<flatbuffers::String> accelerator_name) {
    fbb_.AddOffset(NNAPISettings::VT_ACCELERATOR_NAME, accelerator_name);
  }
  void add_cache_directory(flatbuffers::Offset<flatbuffers::String> cache_directory) {
    fbb_.AddOffset(NNAPISettings::VT_CACHE_DIRECTORY, cache_directory);
  }
  void add_model_token(flatbuffers::Offset<flatbuffers::String> model_token) {
    fbb_.AddOffset(NNAPISettings::VT_MODEL_TOKEN, model_token);
  }
  void add_execution_preference(tflite::NNAPIExecutionPreference execution_preference) {
    fbb_.AddElement<int32_t>(NNAPISettings::VT_EXECUTION_PREFERENCE, static_cast<int32_t>(execution_preference), 0);
  }
  void add_no_of_nnapi_instances_to_cache(int32_t no_of_nnapi_instances_to_cache) {
    fbb_.AddElement<int32_t>(NNAPISettings::VT_NO_OF_NNAPI_INSTANCES_TO_CACHE, no_of_nnapi_instances_to_cache, 0);
  }
  void add_fallback_settings(flatbuffers::Offset<tflite::FallbackSettings> fallback_settings) {
    fbb_.AddOffset(NNAPISettings::VT_FALLBACK_SETTINGS, fallback_settings);
  }
  void add_allow_nnapi_cpu_on_android_10_plus(bool allow_nnapi_cpu_on_android_10_plus) {
    fbb_.AddElement<uint8_t>(NNAPISettings::VT_ALLOW_NNAPI_CPU_ON_ANDROID_10_PLUS, static_cast<uint8_t>(allow_nnapi_cpu_on_android_10_plus), 0);
  }
  void add_execution_priority(tflite::NNAPIExecutionPriority execution_priority) {
    fbb_.AddElement<int32_t>(NNAPISettings::VT_EXECUTION_PRIORITY, static_cast<int32_t>(execution_priority), 0);
  }
  void add_allow_dynamic_dimensions(bool allow_dynamic_dimensions) {
    fbb_.AddElement<uint8_t>(NNAPISettings::VT_ALLOW_DYNAMIC_DIMENSIONS, static_cast<uint8_t>(allow_dynamic_dimensions), 0);
  }
  void add_allow_fp16_precision_for_fp32(bool allow_fp16_precision_for_fp32) {
    fbb_.AddElement<uint8_t>(NNAPISettings::VT_ALLOW_FP16_PRECISION_FOR_FP32, static_cast<uint8_t>(allow_fp16_precision_for_fp32), 0);
  }
  explicit NNAPISettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NNAPISettingsBuilder &operator=(const NNAPISettingsBuilder &);
  flatbuffers::Offset<NNAPISettings> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NNAPISettings>(end);
    return o;
  }
};

inline flatbuffers::Offset<NNAPISettings> CreateNNAPISettings(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> accelerator_name = 0,
    flatbuffers::Offset<flatbuffers::String> cache_directory = 0,
    flatbuffers::Offset<flatbuffers::String> model_token = 0,
    tflite::NNAPIExecutionPreference execution_preference = tflite::NNAPIExecutionPreference_UNDEFINED,
    int32_t no_of_nnapi_instances_to_cache = 0,
    flatbuffers::Offset<tflite::FallbackSettings> fallback_settings = 0,
    bool allow_nnapi_cpu_on_android_10_plus = false,
    tflite::NNAPIExecutionPriority execution_priority = tflite::NNAPIExecutionPriority_NNAPI_PRIORITY_UNDEFINED,
    bool allow_dynamic_dimensions = false,
    bool allow_fp16_precision_for_fp32 = false) {
  NNAPISettingsBuilder builder_(_fbb);
  builder_.add_execution_priority(execution_priority);
  builder_.add_fallback_settings(fallback_settings);
  builder_.add_no_of_nnapi_instances_to_cache(no_of_nnapi_instances_to_cache);
  builder_.add_execution_preference(execution_preference);
  builder_.add_model_token(model_token);
  builder_.add_cache_directory(cache_directory);
  builder_.add_accelerator_name(accelerator_name);
  builder_.add_allow_fp16_precision_for_fp32(allow_fp16_precision_for_fp32);
  builder_.add_allow_dynamic_dimensions(allow_dynamic_dimensions);
  builder_.add_allow_nnapi_cpu_on_android_10_plus(allow_nnapi_cpu_on_android_10_plus);
  return builder_.Finish();
}

inline flatbuffers::Offset<NNAPISettings> CreateNNAPISettingsDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *accelerator_name = nullptr,
    const char *cache_directory = nullptr,
    const char *model_token = nullptr,
    tflite::NNAPIExecutionPreference execution_preference = tflite::NNAPIExecutionPreference_UNDEFINED,
    int32_t no_of_nnapi_instances_to_cache = 0,
    flatbuffers::Offset<tflite::FallbackSettings> fallback_settings = 0,
    bool allow_nnapi_cpu_on_android_10_plus = false,
    tflite::NNAPIExecutionPriority execution_priority = tflite::NNAPIExecutionPriority_NNAPI_PRIORITY_UNDEFINED,
    bool allow_dynamic_dimensions = false,
    bool allow_fp16_precision_for_fp32 = false) {
  auto accelerator_name__ = accelerator_name ? _fbb.CreateString(accelerator_name) : 0;
  auto cache_directory__ = cache_directory ? _fbb.CreateString(cache_directory) : 0;
  auto model_token__ = model_token ? _fbb.CreateString(model_token) : 0;
  return tflite::CreateNNAPISettings(
      _fbb,
      accelerator_name__,
      cache_directory__,
      model_token__,
      execution_preference,
      no_of_nnapi_instances_to_cache,
      fallback_settings,
      allow_nnapi_cpu_on_android_10_plus,
      execution_priority,
      allow_dynamic_dimensions,
      allow_fp16_precision_for_fp32);
}

flatbuffers::Offset<NNAPISettings> CreateNNAPISettings(flatbuffers::FlatBufferBuilder &_fbb, const NNAPISettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct GPUSettingsT : public flatbuffers::NativeTable {
  typedef GPUSettings TableType;
  bool is_precision_loss_allowed;
  bool enable_quantized_inference;
  tflite::GPUBackend force_backend;
  GPUSettingsT()
      : is_precision_loss_allowed(false),
        enable_quantized_inference(true),
        force_backend(tflite::GPUBackend_UNSET) {
  }
};

struct GPUSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef GPUSettingsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_IS_PRECISION_LOSS_ALLOWED = 4,
    VT_ENABLE_QUANTIZED_INFERENCE = 6,
    VT_FORCE_BACKEND = 8
  };
  bool is_precision_loss_allowed() const {
    return GetField<uint8_t>(VT_IS_PRECISION_LOSS_ALLOWED, 0) != 0;
  }
  bool enable_quantized_inference() const {
    return GetField<uint8_t>(VT_ENABLE_QUANTIZED_INFERENCE, 1) != 0;
  }
  tflite::GPUBackend force_backend() const {
    return static_cast<tflite::GPUBackend>(GetField<int32_t>(VT_FORCE_BACKEND, 0));
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint8_t>(verifier, VT_IS_PRECISION_LOSS_ALLOWED) &&
           VerifyField<uint8_t>(verifier, VT_ENABLE_QUANTIZED_INFERENCE) &&
           VerifyField<int32_t>(verifier, VT_FORCE_BACKEND) &&
           verifier.EndTable();
  }
  GPUSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(GPUSettingsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<GPUSettings> Pack(flatbuffers::FlatBufferBuilder &_fbb, const GPUSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct GPUSettingsBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_is_precision_loss_allowed(bool is_precision_loss_allowed) {
    fbb_.AddElement<uint8_t>(GPUSettings::VT_IS_PRECISION_LOSS_ALLOWED, static_cast<uint8_t>(is_precision_loss_allowed), 0);
  }
  void add_enable_quantized_inference(bool enable_quantized_inference) {
    fbb_.AddElement<uint8_t>(GPUSettings::VT_ENABLE_QUANTIZED_INFERENCE, static_cast<uint8_t>(enable_quantized_inference), 1);
  }
  void add_force_backend(tflite::GPUBackend force_backend) {
    fbb_.AddElement<int32_t>(GPUSettings::VT_FORCE_BACKEND, static_cast<int32_t>(force_backend), 0);
  }
  explicit GPUSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  GPUSettingsBuilder &operator=(const GPUSettingsBuilder &);
  flatbuffers::Offset<GPUSettings> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<GPUSettings>(end);
    return o;
  }
};

inline flatbuffers::Offset<GPUSettings> CreateGPUSettings(
    flatbuffers::FlatBufferBuilder &_fbb,
    bool is_precision_loss_allowed = false,
    bool enable_quantized_inference = true,
    tflite::GPUBackend force_backend = tflite::GPUBackend_UNSET) {
  GPUSettingsBuilder builder_(_fbb);
  builder_.add_force_backend(force_backend);
  builder_.add_enable_quantized_inference(enable_quantized_inference);
  builder_.add_is_precision_loss_allowed(is_precision_loss_allowed);
  return builder_.Finish();
}

flatbuffers::Offset<GPUSettings> CreateGPUSettings(flatbuffers::FlatBufferBuilder &_fbb, const GPUSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct HexagonSettingsT : public flatbuffers::NativeTable {
  typedef HexagonSettings TableType;
  int32_t debug_level;
  int32_t powersave_level;
  bool print_graph_profile;
  bool print_graph_debug;
  HexagonSettingsT()
      : debug_level(0),
        powersave_level(0),
        print_graph_profile(false),
        print_graph_debug(false) {
  }
};

struct HexagonSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef HexagonSettingsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DEBUG_LEVEL = 4,
    VT_POWERSAVE_LEVEL = 6,
    VT_PRINT_GRAPH_PROFILE = 8,
    VT_PRINT_GRAPH_DEBUG = 10
  };
  int32_t debug_level() const {
    return GetField<int32_t>(VT_DEBUG_LEVEL, 0);
  }
  int32_t powersave_level() const {
    return GetField<int32_t>(VT_POWERSAVE_LEVEL, 0);
  }
  bool print_graph_profile() const {
    return GetField<uint8_t>(VT_PRINT_GRAPH_PROFILE, 0) != 0;
  }
  bool print_graph_debug() const {
    return GetField<uint8_t>(VT_PRINT_GRAPH_DEBUG, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, VT_DEBUG_LEVEL) &&
           VerifyField<int32_t>(verifier, VT_POWERSAVE_LEVEL) &&
           VerifyField<uint8_t>(verifier, VT_PRINT_GRAPH_PROFILE) &&
           VerifyField<uint8_t>(verifier, VT_PRINT_GRAPH_DEBUG) &&
           verifier.EndTable();
  }
  HexagonSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(HexagonSettingsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<HexagonSettings> Pack(flatbuffers::FlatBufferBuilder &_fbb, const HexagonSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct HexagonSettingsBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_debug_level(int32_t debug_level) {
    fbb_.AddElement<int32_t>(HexagonSettings::VT_DEBUG_LEVEL, debug_level, 0);
  }
  void add_powersave_level(int32_t powersave_level) {
    fbb_.AddElement<int32_t>(HexagonSettings::VT_POWERSAVE_LEVEL, powersave_level, 0);
  }
  void add_print_graph_profile(bool print_graph_profile) {
    fbb_.AddElement<uint8_t>(HexagonSettings::VT_PRINT_GRAPH_PROFILE, static_cast<uint8_t>(print_graph_profile), 0);
  }
  void add_print_graph_debug(bool print_graph_debug) {
    fbb_.AddElement<uint8_t>(HexagonSettings::VT_PRINT_GRAPH_DEBUG, static_cast<uint8_t>(print_graph_debug), 0);
  }
  explicit HexagonSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  HexagonSettingsBuilder &operator=(const HexagonSettingsBuilder &);
  flatbuffers::Offset<HexagonSettings> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<HexagonSettings>(end);
    return o;
  }
};

inline flatbuffers::Offset<HexagonSettings> CreateHexagonSettings(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t debug_level = 0,
    int32_t powersave_level = 0,
    bool print_graph_profile = false,
    bool print_graph_debug = false) {
  HexagonSettingsBuilder builder_(_fbb);
  builder_.add_powersave_level(powersave_level);
  builder_.add_debug_level(debug_level);
  builder_.add_print_graph_debug(print_graph_debug);
  builder_.add_print_graph_profile(print_graph_profile);
  return builder_.Finish();
}

flatbuffers::Offset<HexagonSettings> CreateHexagonSettings(flatbuffers::FlatBufferBuilder &_fbb, const HexagonSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct XNNPackSettingsT : public flatbuffers::NativeTable {
  typedef XNNPackSettings TableType;
  int32_t num_threads;
  XNNPackSettingsT()
      : num_threads(0) {
  }
};

struct XNNPackSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef XNNPackSettingsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_NUM_THREADS = 4
  };
  int32_t num_threads() const {
    return GetField<int32_t>(VT_NUM_THREADS, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, VT_NUM_THREADS) &&
           verifier.EndTable();
  }
  XNNPackSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(XNNPackSettingsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<XNNPackSettings> Pack(flatbuffers::FlatBufferBuilder &_fbb, const XNNPackSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct XNNPackSettingsBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_num_threads(int32_t num_threads) {
    fbb_.AddElement<int32_t>(XNNPackSettings::VT_NUM_THREADS, num_threads, 0);
  }
  explicit XNNPackSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  XNNPackSettingsBuilder &operator=(const XNNPackSettingsBuilder &);
  flatbuffers::Offset<XNNPackSettings> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<XNNPackSettings>(end);
    return o;
  }
};

inline flatbuffers::Offset<XNNPackSettings> CreateXNNPackSettings(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t num_threads = 0) {
  XNNPackSettingsBuilder builder_(_fbb);
  builder_.add_num_threads(num_threads);
  return builder_.Finish();
}

flatbuffers::Offset<XNNPackSettings> CreateXNNPackSettings(flatbuffers::FlatBufferBuilder &_fbb, const XNNPackSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct EdgeTpuSettingsT : public flatbuffers::NativeTable {
  typedef EdgeTpuSettings TableType;
  tflite::EdgeTpuSettings_::PowerState inference_power_state;
  EdgeTpuSettingsT()
      : inference_power_state(tflite::EdgeTpuSettings_::PowerState_UNDEFINED) {
  }
};

struct EdgeTpuSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef EdgeTpuSettingsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INFERENCE_POWER_STATE = 4
  };
  tflite::EdgeTpuSettings_::PowerState inference_power_state() const {
    return static_cast<tflite::EdgeTpuSettings_::PowerState>(GetField<int32_t>(VT_INFERENCE_POWER_STATE, 0));
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, VT_INFERENCE_POWER_STATE) &&
           verifier.EndTable();
  }
  EdgeTpuSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(EdgeTpuSettingsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<EdgeTpuSettings> Pack(flatbuffers::FlatBufferBuilder &_fbb, const EdgeTpuSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct EdgeTpuSettingsBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_inference_power_state(tflite::EdgeTpuSettings_::PowerState inference_power_state) {
    fbb_.AddElement<int32_t>(EdgeTpuSettings::VT_INFERENCE_POWER_STATE, static_cast<int32_t>(inference_power_state), 0);
  }
  explicit EdgeTpuSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  EdgeTpuSettingsBuilder &operator=(const EdgeTpuSettingsBuilder &);
  flatbuffers::Offset<EdgeTpuSettings> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<EdgeTpuSettings>(end);
    return o;
  }
};

inline flatbuffers::Offset<EdgeTpuSettings> CreateEdgeTpuSettings(
    flatbuffers::FlatBufferBuilder &_fbb,
    tflite::EdgeTpuSettings_::PowerState inference_power_state = tflite::EdgeTpuSettings_::PowerState_UNDEFINED) {
  EdgeTpuSettingsBuilder builder_(_fbb);
  builder_.add_inference_power_state(inference_power_state);
  return builder_.Finish();
}

flatbuffers::Offset<EdgeTpuSettings> CreateEdgeTpuSettings(flatbuffers::FlatBufferBuilder &_fbb, const EdgeTpuSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct CPUSettingsT : public flatbuffers::NativeTable {
  typedef CPUSettings TableType;
  int32_t num_threads;
  CPUSettingsT()
      : num_threads(0) {
  }
};

struct CPUSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef CPUSettingsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_NUM_THREADS = 4
  };
  int32_t num_threads() const {
    return GetField<int32_t>(VT_NUM_THREADS, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, VT_NUM_THREADS) &&
           verifier.EndTable();
  }
  CPUSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(CPUSettingsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<CPUSettings> Pack(flatbuffers::FlatBufferBuilder &_fbb, const CPUSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct CPUSettingsBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_num_threads(int32_t num_threads) {
    fbb_.AddElement<int32_t>(CPUSettings::VT_NUM_THREADS, num_threads, 0);
  }
  explicit CPUSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  CPUSettingsBuilder &operator=(const CPUSettingsBuilder &);
  flatbuffers::Offset<CPUSettings> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<CPUSettings>(end);
    return o;
  }
};

inline flatbuffers::Offset<CPUSettings> CreateCPUSettings(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t num_threads = 0) {
  CPUSettingsBuilder builder_(_fbb);
  builder_.add_num_threads(num_threads);
  return builder_.Finish();
}

flatbuffers::Offset<CPUSettings> CreateCPUSettings(flatbuffers::FlatBufferBuilder &_fbb, const CPUSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct TFLiteSettingsT : public flatbuffers::NativeTable {
  typedef TFLiteSettings TableType;
  tflite::Delegate delegate;
  std::unique_ptr<tflite::NNAPISettingsT> nnapi_settings;
  std::unique_ptr<tflite::GPUSettingsT> gpu_settings;
  std::unique_ptr<tflite::HexagonSettingsT> hexagon_settings;
  std::unique_ptr<tflite::XNNPackSettingsT> xnnpack_settings;
  std::unique_ptr<tflite::CPUSettingsT> cpu_settings;
  int32_t max_delegated_partitions;
  std::unique_ptr<tflite::EdgeTpuSettingsT> edgetpu_settings;
  std::unique_ptr<tflite::FallbackSettingsT> fallback_settings;
  TFLiteSettingsT()
      : delegate(tflite::Delegate_NONE),
        max_delegated_partitions(0) {
  }
};

struct TFLiteSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef TFLiteSettingsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DELEGATE = 4,
    VT_NNAPI_SETTINGS = 6,
    VT_GPU_SETTINGS = 8,
    VT_HEXAGON_SETTINGS = 10,
    VT_XNNPACK_SETTINGS = 12,
    VT_CPU_SETTINGS = 14,
    VT_MAX_DELEGATED_PARTITIONS = 16,
    VT_EDGETPU_SETTINGS = 18,
    VT_FALLBACK_SETTINGS = 20
  };
  tflite::Delegate delegate() const {
    return static_cast<tflite::Delegate>(GetField<int32_t>(VT_DELEGATE, 0));
  }
  const tflite::NNAPISettings *nnapi_settings() const {
    return GetPointer<const tflite::NNAPISettings *>(VT_NNAPI_SETTINGS);
  }
  const tflite::GPUSettings *gpu_settings() const {
    return GetPointer<const tflite::GPUSettings *>(VT_GPU_SETTINGS);
  }
  const tflite::HexagonSettings *hexagon_settings() const {
    return GetPointer<const tflite::HexagonSettings *>(VT_HEXAGON_SETTINGS);
  }
  const tflite::XNNPackSettings *xnnpack_settings() const {
    return GetPointer<const tflite::XNNPackSettings *>(VT_XNNPACK_SETTINGS);
  }
  const tflite::CPUSettings *cpu_settings() const {
    return GetPointer<const tflite::CPUSettings *>(VT_CPU_SETTINGS);
  }
  int32_t max_delegated_partitions() const {
    return GetField<int32_t>(VT_MAX_DELEGATED_PARTITIONS, 0);
  }
  const tflite::EdgeTpuSettings *edgetpu_settings() const {
    return GetPointer<const tflite::EdgeTpuSettings *>(VT_EDGETPU_SETTINGS);
  }
  const tflite::FallbackSettings *fallback_settings() const {
    return GetPointer<const tflite::FallbackSettings *>(VT_FALLBACK_SETTINGS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, VT_DELEGATE) &&
           VerifyOffset(verifier, VT_NNAPI_SETTINGS) &&
           verifier.VerifyTable(nnapi_settings()) &&
           VerifyOffset(verifier, VT_GPU_SETTINGS) &&
           verifier.VerifyTable(gpu_settings()) &&
           VerifyOffset(verifier, VT_HEXAGON_SETTINGS) &&
           verifier.VerifyTable(hexagon_settings()) &&
           VerifyOffset(verifier, VT_XNNPACK_SETTINGS) &&
           verifier.VerifyTable(xnnpack_settings()) &&
           VerifyOffset(verifier, VT_CPU_SETTINGS) &&
           verifier.VerifyTable(cpu_settings()) &&
           VerifyField<int32_t>(verifier, VT_MAX_DELEGATED_PARTITIONS) &&
           VerifyOffset(verifier, VT_EDGETPU_SETTINGS) &&
           verifier.VerifyTable(edgetpu_settings()) &&
           VerifyOffset(verifier, VT_FALLBACK_SETTINGS) &&
           verifier.VerifyTable(fallback_settings()) &&
           verifier.EndTable();
  }
  TFLiteSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(TFLiteSettingsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<TFLiteSettings> Pack(flatbuffers::FlatBufferBuilder &_fbb, const TFLiteSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct TFLiteSettingsBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_delegate(tflite::Delegate delegate) {
    fbb_.AddElement<int32_t>(TFLiteSettings::VT_DELEGATE, static_cast<int32_t>(delegate), 0);
  }
  void add_nnapi_settings(flatbuffers::Offset<tflite::NNAPISettings> nnapi_settings) {
    fbb_.AddOffset(TFLiteSettings::VT_NNAPI_SETTINGS, nnapi_settings);
  }
  void add_gpu_settings(flatbuffers::Offset<tflite::GPUSettings> gpu_settings) {
    fbb_.AddOffset(TFLiteSettings::VT_GPU_SETTINGS, gpu_settings);
  }
  void add_hexagon_settings(flatbuffers::Offset<tflite::HexagonSettings> hexagon_settings) {
    fbb_.AddOffset(TFLiteSettings::VT_HEXAGON_SETTINGS, hexagon_settings);
  }
  void add_xnnpack_settings(flatbuffers::Offset<tflite::XNNPackSettings> xnnpack_settings) {
    fbb_.AddOffset(TFLiteSettings::VT_XNNPACK_SETTINGS, xnnpack_settings);
  }
  void add_cpu_settings(flatbuffers::Offset<tflite::CPUSettings> cpu_settings) {
    fbb_.AddOffset(TFLiteSettings::VT_CPU_SETTINGS, cpu_settings);
  }
  void add_max_delegated_partitions(int32_t max_delegated_partitions) {
    fbb_.AddElement<int32_t>(TFLiteSettings::VT_MAX_DELEGATED_PARTITIONS, max_delegated_partitions, 0);
  }
  void add_edgetpu_settings(flatbuffers::Offset<tflite::EdgeTpuSettings> edgetpu_settings) {
    fbb_.AddOffset(TFLiteSettings::VT_EDGETPU_SETTINGS, edgetpu_settings);
  }
  void add_fallback_settings(flatbuffers::Offset<tflite::FallbackSettings> fallback_settings) {
    fbb_.AddOffset(TFLiteSettings::VT_FALLBACK_SETTINGS, fallback_settings);
  }
  explicit TFLiteSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TFLiteSettingsBuilder &operator=(const TFLiteSettingsBuilder &);
  flatbuffers::Offset<TFLiteSettings> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<TFLiteSettings>(end);
    return o;
  }
};

inline flatbuffers::Offset<TFLiteSettings> CreateTFLiteSettings(
    flatbuffers::FlatBufferBuilder &_fbb,
    tflite::Delegate delegate = tflite::Delegate_NONE,
    flatbuffers::Offset<tflite::NNAPISettings> nnapi_settings = 0,
    flatbuffers::Offset<tflite::GPUSettings> gpu_settings = 0,
    flatbuffers::Offset<tflite::HexagonSettings> hexagon_settings = 0,
    flatbuffers::Offset<tflite::XNNPackSettings> xnnpack_settings = 0,
    flatbuffers::Offset<tflite::CPUSettings> cpu_settings = 0,
    int32_t max_delegated_partitions = 0,
    flatbuffers::Offset<tflite::EdgeTpuSettings> edgetpu_settings = 0,
    flatbuffers::Offset<tflite::FallbackSettings> fallback_settings = 0) {
  TFLiteSettingsBuilder builder_(_fbb);
  builder_.add_fallback_settings(fallback_settings);
  builder_.add_edgetpu_settings(edgetpu_settings);
  builder_.add_max_delegated_partitions(max_delegated_partitions);
  builder_.add_cpu_settings(cpu_settings);
  builder_.add_xnnpack_settings(xnnpack_settings);
  builder_.add_hexagon_settings(hexagon_settings);
  builder_.add_gpu_settings(gpu_settings);
  builder_.add_nnapi_settings(nnapi_settings);
  builder_.add_delegate(delegate);
  return builder_.Finish();
}

flatbuffers::Offset<TFLiteSettings> CreateTFLiteSettings(flatbuffers::FlatBufferBuilder &_fbb, const TFLiteSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct FallbackSettingsT : public flatbuffers::NativeTable {
  typedef FallbackSettings TableType;
  bool allow_automatic_fallback_on_compilation_error;
  bool allow_automatic_fallback_on_execution_error;
  FallbackSettingsT()
      : allow_automatic_fallback_on_compilation_error(false),
        allow_automatic_fallback_on_execution_error(false) {
  }
};

struct FallbackSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FallbackSettingsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ALLOW_AUTOMATIC_FALLBACK_ON_COMPILATION_ERROR = 4,
    VT_ALLOW_AUTOMATIC_FALLBACK_ON_EXECUTION_ERROR = 6
  };
  bool allow_automatic_fallback_on_compilation_error() const {
    return GetField<uint8_t>(VT_ALLOW_AUTOMATIC_FALLBACK_ON_COMPILATION_ERROR, 0) != 0;
  }
  bool allow_automatic_fallback_on_execution_error() const {
    return GetField<uint8_t>(VT_ALLOW_AUTOMATIC_FALLBACK_ON_EXECUTION_ERROR, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint8_t>(verifier, VT_ALLOW_AUTOMATIC_FALLBACK_ON_COMPILATION_ERROR) &&
           VerifyField<uint8_t>(verifier, VT_ALLOW_AUTOMATIC_FALLBACK_ON_EXECUTION_ERROR) &&
           verifier.EndTable();
  }
  FallbackSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(FallbackSettingsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<FallbackSettings> Pack(flatbuffers::FlatBufferBuilder &_fbb, const FallbackSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct FallbackSettingsBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_allow_automatic_fallback_on_compilation_error(bool allow_automatic_fallback_on_compilation_error) {
    fbb_.AddElement<uint8_t>(FallbackSettings::VT_ALLOW_AUTOMATIC_FALLBACK_ON_COMPILATION_ERROR, static_cast<uint8_t>(allow_automatic_fallback_on_compilation_error), 0);
  }
  void add_allow_automatic_fallback_on_execution_error(bool allow_automatic_fallback_on_execution_error) {
    fbb_.AddElement<uint8_t>(FallbackSettings::VT_ALLOW_AUTOMATIC_FALLBACK_ON_EXECUTION_ERROR, static_cast<uint8_t>(allow_automatic_fallback_on_execution_error), 0);
  }
  explicit FallbackSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  FallbackSettingsBuilder &operator=(const FallbackSettingsBuilder &);
  flatbuffers::Offset<FallbackSettings> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FallbackSettings>(end);
    return o;
  }
};

inline flatbuffers::Offset<FallbackSettings> CreateFallbackSettings(
    flatbuffers::FlatBufferBuilder &_fbb,
    bool allow_automatic_fallback_on_compilation_error = false,
    bool allow_automatic_fallback_on_execution_error = false) {
  FallbackSettingsBuilder builder_(_fbb);
  builder_.add_allow_automatic_fallback_on_execution_error(allow_automatic_fallback_on_execution_error);
  builder_.add_allow_automatic_fallback_on_compilation_error(allow_automatic_fallback_on_compilation_error);
  return builder_.Finish();
}

flatbuffers::Offset<FallbackSettings> CreateFallbackSettings(flatbuffers::FlatBufferBuilder &_fbb, const FallbackSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

inline ComputeSettingsT *ComputeSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new ComputeSettingsT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void ComputeSettings::UnPackTo(ComputeSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = preference(); _o->preference = _e; }
  { auto _e = tflite_settings(); if (_e) _o->tflite_settings = std::unique_ptr<tflite::TFLiteSettingsT>(_e->UnPack(_resolver)); }
  { auto _e = model_namespace_for_statistics(); if (_e) _o->model_namespace_for_statistics = _e->str(); }
  { auto _e = model_identifier_for_statistics(); if (_e) _o->model_identifier_for_statistics = _e->str(); }
}

inline flatbuffers::Offset<ComputeSettings> ComputeSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ComputeSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateComputeSettings(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<ComputeSettings> CreateComputeSettings(flatbuffers::FlatBufferBuilder &_fbb, const ComputeSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const ComputeSettingsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _preference = _o->preference;
  auto _tflite_settings = _o->tflite_settings ? CreateTFLiteSettings(_fbb, _o->tflite_settings.get(), _rehasher) : 0;
  auto _model_namespace_for_statistics = _o->model_namespace_for_statistics.empty() ? 0 : _fbb.CreateString(_o->model_namespace_for_statistics);
  auto _model_identifier_for_statistics = _o->model_identifier_for_statistics.empty() ? 0 : _fbb.CreateString(_o->model_identifier_for_statistics);
  return tflite::CreateComputeSettings(
      _fbb,
      _preference,
      _tflite_settings,
      _model_namespace_for_statistics,
      _model_identifier_for_statistics);
}

inline NNAPISettingsT *NNAPISettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new NNAPISettingsT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void NNAPISettings::UnPackTo(NNAPISettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = accelerator_name(); if (_e) _o->accelerator_name = _e->str(); }
  { auto _e = cache_directory(); if (_e) _o->cache_directory = _e->str(); }
  { auto _e = model_token(); if (_e) _o->model_token = _e->str(); }
  { auto _e = execution_preference(); _o->execution_preference = _e; }
  { auto _e = no_of_nnapi_instances_to_cache(); _o->no_of_nnapi_instances_to_cache = _e; }
  { auto _e = fallback_settings(); if (_e) _o->fallback_settings = std::unique_ptr<tflite::FallbackSettingsT>(_e->UnPack(_resolver)); }
  { auto _e = allow_nnapi_cpu_on_android_10_plus(); _o->allow_nnapi_cpu_on_android_10_plus = _e; }
  { auto _e = execution_priority(); _o->execution_priority = _e; }
  { auto _e = allow_dynamic_dimensions(); _o->allow_dynamic_dimensions = _e; }
  { auto _e = allow_fp16_precision_for_fp32(); _o->allow_fp16_precision_for_fp32 = _e; }
}

inline flatbuffers::Offset<NNAPISettings> NNAPISettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NNAPISettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateNNAPISettings(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<NNAPISettings> CreateNNAPISettings(flatbuffers::FlatBufferBuilder &_fbb, const NNAPISettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const NNAPISettingsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _accelerator_name = _o->accelerator_name.empty() ? 0 : _fbb.CreateString(_o->accelerator_name);
  auto _cache_directory = _o->cache_directory.empty() ? 0 : _fbb.CreateString(_o->cache_directory);
  auto _model_token = _o->model_token.empty() ? 0 : _fbb.CreateString(_o->model_token);
  auto _execution_preference = _o->execution_preference;
  auto _no_of_nnapi_instances_to_cache = _o->no_of_nnapi_instances_to_cache;
  auto _fallback_settings = _o->fallback_settings ? CreateFallbackSettings(_fbb, _o->fallback_settings.get(), _rehasher) : 0;
  auto _allow_nnapi_cpu_on_android_10_plus = _o->allow_nnapi_cpu_on_android_10_plus;
  auto _execution_priority = _o->execution_priority;
  auto _allow_dynamic_dimensions = _o->allow_dynamic_dimensions;
  auto _allow_fp16_precision_for_fp32 = _o->allow_fp16_precision_for_fp32;
  return tflite::CreateNNAPISettings(
      _fbb,
      _accelerator_name,
      _cache_directory,
      _model_token,
      _execution_preference,
      _no_of_nnapi_instances_to_cache,
      _fallback_settings,
      _allow_nnapi_cpu_on_android_10_plus,
      _execution_priority,
      _allow_dynamic_dimensions,
      _allow_fp16_precision_for_fp32);
}

inline GPUSettingsT *GPUSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new GPUSettingsT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void GPUSettings::UnPackTo(GPUSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = is_precision_loss_allowed(); _o->is_precision_loss_allowed = _e; }
  { auto _e = enable_quantized_inference(); _o->enable_quantized_inference = _e; }
  { auto _e = force_backend(); _o->force_backend = _e; }
}

inline flatbuffers::Offset<GPUSettings> GPUSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const GPUSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateGPUSettings(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<GPUSettings> CreateGPUSettings(flatbuffers::FlatBufferBuilder &_fbb, const GPUSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const GPUSettingsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _is_precision_loss_allowed = _o->is_precision_loss_allowed;
  auto _enable_quantized_inference = _o->enable_quantized_inference;
  auto _force_backend = _o->force_backend;
  return tflite::CreateGPUSettings(
      _fbb,
      _is_precision_loss_allowed,
      _enable_quantized_inference,
      _force_backend);
}

inline HexagonSettingsT *HexagonSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new HexagonSettingsT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void HexagonSettings::UnPackTo(HexagonSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = debug_level(); _o->debug_level = _e; }
  { auto _e = powersave_level(); _o->powersave_level = _e; }
  { auto _e = print_graph_profile(); _o->print_graph_profile = _e; }
  { auto _e = print_graph_debug(); _o->print_graph_debug = _e; }
}

inline flatbuffers::Offset<HexagonSettings> HexagonSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const HexagonSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateHexagonSettings(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<HexagonSettings> CreateHexagonSettings(flatbuffers::FlatBufferBuilder &_fbb, const HexagonSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const HexagonSettingsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _debug_level = _o->debug_level;
  auto _powersave_level = _o->powersave_level;
  auto _print_graph_profile = _o->print_graph_profile;
  auto _print_graph_debug = _o->print_graph_debug;
  return tflite::CreateHexagonSettings(
      _fbb,
      _debug_level,
      _powersave_level,
      _print_graph_profile,
      _print_graph_debug);
}

inline XNNPackSettingsT *XNNPackSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new XNNPackSettingsT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void XNNPackSettings::UnPackTo(XNNPackSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = num_threads(); _o->num_threads = _e; }
}

inline flatbuffers::Offset<XNNPackSettings> XNNPackSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const XNNPackSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateXNNPackSettings(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<XNNPackSettings> CreateXNNPackSettings(flatbuffers::FlatBufferBuilder &_fbb, const XNNPackSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const XNNPackSettingsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _num_threads = _o->num_threads;
  return tflite::CreateXNNPackSettings(
      _fbb,
      _num_threads);
}

inline EdgeTpuSettingsT *EdgeTpuSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new EdgeTpuSettingsT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void EdgeTpuSettings::UnPackTo(EdgeTpuSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = inference_power_state(); _o->inference_power_state = _e; }
}

inline flatbuffers::Offset<EdgeTpuSettings> EdgeTpuSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const EdgeTpuSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateEdgeTpuSettings(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<EdgeTpuSettings> CreateEdgeTpuSettings(flatbuffers::FlatBufferBuilder &_fbb, const EdgeTpuSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const EdgeTpuSettingsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _inference_power_state = _o->inference_power_state;
  return tflite::CreateEdgeTpuSettings(
      _fbb,
      _inference_power_state);
}

inline CPUSettingsT *CPUSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new CPUSettingsT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void CPUSettings::UnPackTo(CPUSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = num_threads(); _o->num_threads = _e; }
}

inline flatbuffers::Offset<CPUSettings> CPUSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const CPUSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateCPUSettings(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<CPUSettings> CreateCPUSettings(flatbuffers::FlatBufferBuilder &_fbb, const CPUSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const CPUSettingsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _num_threads = _o->num_threads;
  return tflite::CreateCPUSettings(
      _fbb,
      _num_threads);
}

inline TFLiteSettingsT *TFLiteSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new TFLiteSettingsT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void TFLiteSettings::UnPackTo(TFLiteSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = delegate(); _o->delegate = _e; }
  { auto _e = nnapi_settings(); if (_e) _o->nnapi_settings = std::unique_ptr<tflite::NNAPISettingsT>(_e->UnPack(_resolver)); }
  { auto _e = gpu_settings(); if (_e) _o->gpu_settings = std::unique_ptr<tflite::GPUSettingsT>(_e->UnPack(_resolver)); }
  { auto _e = hexagon_settings(); if (_e) _o->hexagon_settings = std::unique_ptr<tflite::HexagonSettingsT>(_e->UnPack(_resolver)); }
  { auto _e = xnnpack_settings(); if (_e) _o->xnnpack_settings = std::unique_ptr<tflite::XNNPackSettingsT>(_e->UnPack(_resolver)); }
  { auto _e = cpu_settings(); if (_e) _o->cpu_settings = std::unique_ptr<tflite::CPUSettingsT>(_e->UnPack(_resolver)); }
  { auto _e = max_delegated_partitions(); _o->max_delegated_partitions = _e; }
  { auto _e = edgetpu_settings(); if (_e) _o->edgetpu_settings = std::unique_ptr<tflite::EdgeTpuSettingsT>(_e->UnPack(_resolver)); }
  { auto _e = fallback_settings(); if (_e) _o->fallback_settings = std::unique_ptr<tflite::FallbackSettingsT>(_e->UnPack(_resolver)); }
}

inline flatbuffers::Offset<TFLiteSettings> TFLiteSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const TFLiteSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateTFLiteSettings(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<TFLiteSettings> CreateTFLiteSettings(flatbuffers::FlatBufferBuilder &_fbb, const TFLiteSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const TFLiteSettingsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _delegate = _o->delegate;
  auto _nnapi_settings = _o->nnapi_settings ? CreateNNAPISettings(_fbb, _o->nnapi_settings.get(), _rehasher) : 0;
  auto _gpu_settings = _o->gpu_settings ? CreateGPUSettings(_fbb, _o->gpu_settings.get(), _rehasher) : 0;
  auto _hexagon_settings = _o->hexagon_settings ? CreateHexagonSettings(_fbb, _o->hexagon_settings.get(), _rehasher) : 0;
  auto _xnnpack_settings = _o->xnnpack_settings ? CreateXNNPackSettings(_fbb, _o->xnnpack_settings.get(), _rehasher) : 0;
  auto _cpu_settings = _o->cpu_settings ? CreateCPUSettings(_fbb, _o->cpu_settings.get(), _rehasher) : 0;
  auto _max_delegated_partitions = _o->max_delegated_partitions;
  auto _edgetpu_settings = _o->edgetpu_settings ? CreateEdgeTpuSettings(_fbb, _o->edgetpu_settings.get(), _rehasher) : 0;
  auto _fallback_settings = _o->fallback_settings ? CreateFallbackSettings(_fbb, _o->fallback_settings.get(), _rehasher) : 0;
  return tflite::CreateTFLiteSettings(
      _fbb,
      _delegate,
      _nnapi_settings,
      _gpu_settings,
      _hexagon_settings,
      _xnnpack_settings,
      _cpu_settings,
      _max_delegated_partitions,
      _edgetpu_settings,
      _fallback_settings);
}

inline FallbackSettingsT *FallbackSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new FallbackSettingsT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void FallbackSettings::UnPackTo(FallbackSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = allow_automatic_fallback_on_compilation_error(); _o->allow_automatic_fallback_on_compilation_error = _e; }
  { auto _e = allow_automatic_fallback_on_execution_error(); _o->allow_automatic_fallback_on_execution_error = _e; }
}

inline flatbuffers::Offset<FallbackSettings> FallbackSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const FallbackSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateFallbackSettings(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<FallbackSettings> CreateFallbackSettings(flatbuffers::FlatBufferBuilder &_fbb, const FallbackSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const FallbackSettingsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _allow_automatic_fallback_on_compilation_error = _o->allow_automatic_fallback_on_compilation_error;
  auto _allow_automatic_fallback_on_execution_error = _o->allow_automatic_fallback_on_execution_error;
  return tflite::CreateFallbackSettings(
      _fbb,
      _allow_automatic_fallback_on_compilation_error,
      _allow_automatic_fallback_on_execution_error);
}

}  // namespace tflite

#endif  // FLATBUFFERS_GENERATED_CONFIGURATION_TFLITE_H_
